{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating coniii mft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_data import voting_data as samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as la\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = (np.array(samples) + 1.0)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(samples[0])\n",
    "N = len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooccurrence_matrix(samples):\n",
    "    \"\"\" Takes the DATA samples, returns the cooccurrence matrix. The samples must be in the {0, 1} \n",
    "    basis. The cooccurrence matrix is the \"\"\"\n",
    "    return(samples.T @ samples / len(samples))\n",
    "\n",
    "def replaceDiag(mat, lst):\n",
    "    \"\"\" Replaces the diagonal of a matrix mat with lst \"\"\"\n",
    "    return(mat - sp.diag(sp.diag(mat)) + sp.diag(lst))\n",
    "\n",
    "def get_regularized_MF_J(samples, mean_field_prior_lambda):\n",
    "    cooc = cooccurrence_matrix(samples)\n",
    "    freqs = sp.diag(cooc) # These are the pi, pj\n",
    "    c = cooc - sp.outer(freqs, freqs) # This is pij - pi pj\n",
    "    \n",
    "    Mdenom = sp.sqrt(sp.outer(freqs * (1.-freqs), freqs * (1. - freqs)))\n",
    "    M = c / Mdenom # This is just the correlations.\n",
    "\n",
    "    # Calculating off diagonal J elements\n",
    "    #mean_field_prior_lambda = 0\n",
    "    gamma = mean_field_prior_lambda / len(samples)\n",
    "    mq, vq = la.eig(M)\n",
    "    mqhat = 0.5*(mq - gamma + sp.sqrt((mq - gamma)**2 + 4. * gamma))\n",
    "    jq = 1.0 / mqhat\n",
    "    Jprime = sp.real_if_close(sp.dot(vq, sp.dot(sp.diag(jq) , vq.T)))\n",
    "    JMF = replaceDiag(Jprime / Mdenom, sp.zeros(n))\n",
    "    \n",
    "    # Diagonal J elements -- can we not just set these to 0?\n",
    "    piFactor = sp.repeat( [(freqs-0.5)/(freqs*(1.-freqs))], n, axis=0).T\n",
    "    pjFactor = sp.repeat([freqs], n, axis=0)\n",
    "    factor2 = c * piFactor - pjFactor\n",
    "    hMF = sp.diag( sp.dot(JMF, factor2.T)).copy()\n",
    "    hMF -= sp.log(freqs/(1.-freqs))\n",
    "\n",
    "    J = replaceDiag(0.5*JMF, hMF)\n",
    "    \n",
    "    return(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc = cooccurrence_matrix(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're using an upper triangular cooccurrence matrix. There's also a cluster term, but they take the cluster to be the length o the coocurrence matrix. I think this means that they just reused code from the cluster expansion (which looks awesome, and you should learn about it) and set the cluster to be the full length of all the spins. For mean field theory, they stop using an upper triangular matrix, so we don't need to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooc_stdevs(cooc_matrix, num_samples):\n",
    "    \"\"\" Returns a list of variances of the samples using Laplace's Method (rule of succession)\"\"\"\n",
    "    coocBayesianMean = (cooc*num_samples + 1.0) / (2.0 + num_samples) # Laplace's Rule\n",
    "    return(sp.sqrt(coocBayesianMean * (1.-coocBayesianMean)/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_stdev = cooc_stdevs(cooc, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to find the upper triangular indices so we don't count everything twice. \n",
    "a[np.triu_indices(3, k = 0 or 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqsList = np.diag(cooc)\n",
    "pmean = np.mean(freqsList)\n",
    "N = len(samples)\n",
    "n = len(cooc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(J, num_samples = 20*N, T = 2.0):\n",
    "    \"\"\" Wrapper function to obtain the samples \"\"\"\n",
    "    start_state = np.random.choice([-1,1], size=n)\n",
    "    ising_samples = fast.cfast_sample(start_state, J, num_samples = num_samples, T=T)\n",
    "    return(ising_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't think we'll need to use this.\n",
    "def convert_params(J, convert_to, concat=False):\n",
    "    \"\"\"Convert Ising model fields and couplings from {0,1} basis to {-1,1} and vice versa. convert_to\n",
    "    should be either '01' or '11'\n",
    "    \"\"\"\n",
    "    if convert_to == '11':\n",
    "        Jp = J / 4.\n",
    "    elif convert_to == '01':\n",
    "        Jp = J * 4.\n",
    "\n",
    "    return([hp, Jp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 ms, sys: 554 Âµs, total: 3.19 ms\n",
      "Wall time: 2.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "J_ = get_regularized_MF_J(samples,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_samples(J_, T = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc= cooccurrence_matrix(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = np.loadtxt(\"jij_correct_solution.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_ = get_regularized_MF_J(samples,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_samples(J_, num_samples=16000, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizer_func(mean_field_prior_gamma):\n",
    "    \"\"\"meanFieldGamma is the strength of the Ising problem. We translate ot the QUBO problem,\n",
    "    extract the coocurrence matrix of the samples, and compare it to the coocurrence matrix of\n",
    "    the data. \"\"\"\n",
    "    mean_field_prior_lambda = mean_field_prior_gamma / (pmean**2 * (1.-pmean)**2) # I don't know where this comes from\n",
    "    J = get_regularized_MF_J(cooc, mean_field_prior_lambda)\n",
    "    ising_samples = get_samples(J, T = 10)[1]\n",
    "    print(\"Acquired samples\")\n",
    "    qubo_samples = (ising_samples + 1.0) / 2.0\n",
    "    \n",
    "    sample_cooc = cooccurrence_matrix(qubo_samples)\n",
    "    diff = (cooc - sample_cooc) / cooc_stdev\n",
    "    dc = diff[np.triu_indices(n)]\n",
    "    return(sp.sum(dc ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_solution_to_ising(gamma_sol):\n",
    "    mean_field_lambda = gamma_sol / (pmean**2 * (1.-pmean)**2)\n",
    "    J = get_regularized_MF_J(cooc, mean_field_lambda, N)\n",
    "    J = J + J.T\n",
    "    # convert J to {-1,1} basis\n",
    "    h = np.diag(-J)\n",
    "    J = J - np.diag(np.diag(J))\n",
    "    final_J = convert_params(h, J*2, '11')\n",
    "    return(final_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-bdead1b7e5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-b11070bb2b7f>\u001b[0m in \u001b[0;36mget_samples\u001b[0;34m(J, num_samples, T)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\" Wrapper function to obtain the samples \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mising_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfast_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mising_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/warroom/into-the-wild/scotus/fast.pyx\u001b[0m in \u001b[0;36mfast.cfast_sample\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deepcopy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \"\"\"Shallow copy operation on arbitrary Python objects.\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = get_samples(J_, num_samples=16000, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_ = get_regularized_MF_J(cooc, 0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
